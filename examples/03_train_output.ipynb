{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will go over the steps on how to optimize thet parameters of a network with gradient descent using PyTorch optimizers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "\n",
    "# PhotonTorch\n",
    "import photontorch as pt\n",
    "\n",
    "# Progress Bars\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Michelson Interferometer Cavity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schematic\n",
    "<img src='images/michelson.png' width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation and Design Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neff = np.sqrt(12.1)\n",
    "wl = 1.55e-6\n",
    "dt = 0.5e-9\n",
    "total_time = 2e-6\n",
    "time = np.arange(0,total_time,dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the network again in the standard way. However, sometimes it is useful to define components only once, but save copies of the component while setting it as an attribute of the network.\n",
    "\n",
    "Look for example at the line\n",
    "```\n",
    "self.m_west = self.m_north = self.m_east = self.m_south = pt.Mirror(R=0.9)\n",
    "```\n",
    "In standard python, the same `Mirror` component would be set to the attributes of the network `m_west`, `m_north`, `m_east` and `m_south`. However, if the flag `copy_components=True` is set during initialization, a deep copy of the components will be made before they are set as attributes of the network. Effectively making sure that all components of the network will have distinct parameters that can be updated seperately of each other.\n",
    "\n",
    "Test this for yourself by removing the `copy_components=True` flag below. See what effect it has on the number of parameters and on the final result of the optimized network.\n",
    "\n",
    "Note that the order of the detectors is defined by where they appear in the link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network in the standard way:\n",
    "class MichelsonCavity(pt.Network):\n",
    "    def __init__(self):\n",
    "        super(MichelsonCavity, self).__init__(copy_components=True)\n",
    "        self.west = pt.Source()\n",
    "        self.north = self.east = self.south = pt.Detector()\n",
    "        self.m_west = self.m_north = self.m_east = self.m_south = pt.Mirror(R=0.9)\n",
    "        self.wg_west = pt.Waveguide(0.43, neff=neff)\n",
    "        self.wg_north = pt.Waveguide(0.60, neff=neff)\n",
    "        self.wg_east = pt.Waveguide(0.95, neff=neff)\n",
    "        self.wg_south = pt.Waveguide(1.12, neff=neff)\n",
    "        self.dc = pt.DirectionalCoupler(coupling=0.5)\n",
    "        self.link('west:0','0:m_west:1', '0:wg_west:1', '0:dc:2', '0:wg_east:1', '0:m_east:1', '0:east')\n",
    "        self.link('north:0', '0:m_north:1', '0:wg_north:1', '1:dc:3', '0:wg_south:1', '0:m_south:1', '0:south')\n",
    "    \n",
    "# create network\n",
    "nw = MichelsonCavity()\n",
    "\n",
    "# print out the parameters of the network:\n",
    "for p in nw.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with pt.Environment(wavelength=wl, t=time):\n",
    "    detected = nw(source=1)[:,0,:,0] # get all timesteps, the only wavelength, all detectors, the only batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw.plot(detected);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10 # number of training cycles\n",
    "learning_rate = 0.2 # multiplication factor for the gradients during optimization.\n",
    "lossfunc = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(nw.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to train the network to arrive in another steady state with the same output everywhere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_power_out = detected.data.cpu().numpy()[-1].sum()\n",
    "target = np.ones(3)*total_power_out/3\n",
    "# The target should be a torch variable.\n",
    "# You can create a new torch variable with the right type and cuda type, straight from the network itself:\n",
    "target = torch.tensor(target, device=nw.device, dtype=torch.get_default_dtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start the training. However, to be able to train the parameters of the network, gradient tracking should be enabled in the simulation environment. This is done by setting the `enable_grad` flag to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop over the training cycles:\n",
    "with pt.Environment(wavelength=wl, t=time, enable_grad=True):\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        optimizer.zero_grad()\n",
    "        detected = nw(source=1)[-1,0,:,0] # get the last timestep, the only wavelength, all detectors, the only batch\n",
    "        loss = lossfunc(detected, target) # calculate the loss (error) between detected and target\n",
    "        loss.backward() # calculate the resulting gradients for all the parameters of the network\n",
    "        optimizer.step() # update the networks parameters with the gradients\n",
    "        del detected, loss # free up memory (important for GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a final simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pt.Environment(wavelength=wl, t=time):\n",
    "    detected = nw(source=1) # get all timesteps, the only wavelength, all detectors, the only batch\n",
    "    nw.plot(detected);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
